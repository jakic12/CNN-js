!function(e){var t={};function r(s){if(t[s])return t[s].exports;var h=t[s]={i:s,l:!1,exports:{}};return e[s].call(h.exports,h,h.exports,r),h.l=!0,h.exports}r.m=e,r.c=t,r.d=function(e,t,s){r.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:s})},r.r=function(e){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},r.t=function(e,t){if(1&t&&(e=r(e)),8&t)return e;if(4&t&&"object"==typeof e&&e&&e.__esModule)return e;var s=Object.create(null);if(r.r(s),Object.defineProperty(s,"default",{enumerable:!0,value:e}),2&t&&"string"!=typeof e)for(var h in e)r.d(s,h,function(t){return e[t]}.bind(null,h));return s},r.n=function(e){var t=e&&e.__esModule?function(){return e.default}:function(){return e};return r.d(t,"a",t),t},r.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},r.p="",r(r.s=0)}([function(e,t,r){const{CNN:s}=r(1);self.addEventListener("message",e=>{const t=new s(JSON.parse(e.data.network)),r=(e,r)=>{self.postMessage({event:e,data:r,network:JSON.stringify(t)})};t.sgd(Object.assign(e.data.trainingProps,{onProgress:(...e)=>r("batchProgress",e),onEnd:(...e)=>r("end",e)}))})},function(e,t,r){"use strict";var{matrixMultiply:s,matrixDot:h,transpose:a,convolute:i,doubleInverse:n,correlate:l,getDimension:o,maxPool:p,flattenDeep:f,matrixAdd:d,deepMap:g,backPropagateCorrelation:u,update2Dmatrix:y,maxIndex:w}=r(2);const c=e=>1/(1+Math.exp(-e)),m={RELU:{norm:e=>e>0?e:0,derivative:e=>e>0?1:0},SIGMOID:{norm:c,derivative:e=>c(e)*(1-c(e))},TANH:{norm:Math.tanh,derivative:e=>1-Math.pow(Math.tanh(e),2)}};class N{constructor(e){if(e.shape)N.confirmShape(e.shape),this.initialShape=e.initialShape.map(e=>Object.assign({},e)),this.shape=N.applyActivationFunctionToShape(e.initialShape),this.errorF=(e,t)=>Math.pow(t-e,2)/2,this.dErrorF=(e,t)=>t-e,this.learningRate=e.learningRate,this.layers=e.layers,this.dlayers=e.dlayers,this.weights=e.weights,this.biases=e.biases;else{N.confirmShape(e),this.initialShape=e.map(e=>Object.assign({},e)),this.shape=N.applyActivationFunctionToShape(e);const t=(e,t)=>Math.random()*Math.sqrt(6/(e+t)),r=(e,t)=>(2*Math.random()-1)*Math.sqrt(2/e),s=()=>0;this.errorF=(e,t)=>Math.pow(t-e,2)/2,this.dErrorF=(e,t)=>t-e,this.learningRate=-.01,this.layers=new Array(e.length).fill(0).map((t,r)=>e[r].type==A.FC||e[r].type==A.FLATTEN?new Array(e[r].l).fill(0):new Array(e[r].d).fill(0).map(()=>new Array(e[r].h).fill(0).map(()=>new Array(e[r].w).fill(0)))),this.dlayers=[],this.weights=new Array(e.length).fill(0).map((s,h)=>{if(0!=h){if(e[h].type==A.FC)return new Array(e[h-1].l).fill(0).map(()=>new Array(e[h].l).fill(0).map(r=>t(e[h-1].l,e[h].l)));if(e[h].type==A.CONV)return new Array(e[h].k).fill(0).map(()=>new Array(e[h-1].d).fill(0).map(()=>new Array(e[h].f).fill(0).map(()=>new Array(e[h].f).fill(0).map((t,s)=>r(e[h-1].w*e[h-1].d*e[h-1].h)))))}}),this.biases=new Array(e.length).fill(0).map((t,r)=>{if(0!=r)return e[r].type==A.FC?new Array(this.shape[r].l).fill(0).map(s):new Array(this.shape[r].d).fill(0).map(s)})}}static applyActivationFunctionToShape(e){return e.map(e=>e.afName?Object.assign(e,{af:m[e.afName].norm,daf:m[e.afName].derivative}):e)}sgd({dataset:e,epochs:t,learningRate:r=this.learningRate,decay:s=0,onProgress:h,onEnd:a}){this.learningRate=r;for(let a=0;a<t;a++){let t=0,i=0;for(let r=0;r<e.length;r++){let s=this.forwardPropagate(e[r].input);this.backpropagate(e[r].output),this.updateWeights(),t+=this.getError(e[r].output),w(s)===w(e[r].output)&&i++}h&&h(a,i/e.length,t/e.length,this.learningRate),this.learningRate=r/(1+s*a)}a&&a()}forwardPropagate(e){if(e.length!=this.shape[0].d)throw new Error(`data depth (${e.length}) doesnt match required depth (${this.shape[0].d})`);if(e[0].length!=this.shape[0].h)throw new Error(`data height (${e[0].length}) doesnt match required height (${this.shape[0].h})`);if(e[0][0].length!=this.shape[0].w)throw new Error(`data width (${e[0][0].length}) doesnt match required width (${this.shape[0].w})`);this.layers[0]=e;for(let e=1;e<this.shape.length;e++){switch(this.shape[e].type){case A.CONV:this.layers[e]=l(this.layers[e-1],this.weights[e],this.shape[e].s,this.shape[e].p,this.biases[e]);break;case A.POOL:this.layers[e]=p(this.layers[e-1],this.shape[e].f,this.shape[e].s);break;case A.FLATTEN:this.layers[e]=f(this.layers[e-1]);break;case A.FC:this.layers[e]=d(h([this.layers[e-1]],this.weights[e])[0],this.biases[e])}g(this.layers[e],(e,t,r)=>{if(isNaN(e))throw new Error(`[${t}] output NaN before activation`);return e}),this.shape[e].af&&(this.layers[e]=g(this.layers[e],t=>this.shape[e].af(t))),g(this.layers[e],t=>{if(isNaN(t))throw new Error(`[${e}] output NaN after activation`);return t})}return this.layers[this.layers.length-1]}getError(e,t=!1){if(e.length!=this.shape[this.shape.length-1].l)throw new Error(`expected array length (${e.length}) doesn't equal last layer length (${this.shape[this.shape.length-1].l})`);let r=this.layers[this.shape.length-1].map((t,r)=>this.errorF(e[r],t));return this.error=r.reduce((e,t)=>e+t,0)/this.layers[this.shape.length-1].length,t?r:this.error}backpropagate(e,t=!1){if(e.length!=this.shape[this.shape.length-1].l)throw new Error(`expected array length (${e.length}) doesn't equal last layer length (${this.shape[this.shape.length-1].l})`);for(let r=this.shape.length-1;r>0;r--){if(this.shape[r].type==A.FC){if(r==this.shape.length-1?this.dlayers[r]=this.layers[r].map((t,r)=>this.dErrorF(e[r],t)):this.dlayers[r]=h([this.dlayers[r+1]],a(this.weights[r+1]))[0],this.shape[r].daf&&(this.dlayers[r]=s(this.dlayers[r],g(this.layers[r],e=>this.shape[r].daf(e)))),t)for(let e=0;e<this.weights[r].length;e++)for(let t=0;t<this.weights[r][e].length;t++)this.weights[r][e][t]+=this.layers[r-1][e]*this.dlayers[r][t]*this.learningRate}else if(this.shape[r].type==A.FLATTEN){let t;t=r==this.shape.length-1?this.layers[r].map((t,r)=>this.dErrorF(e[r],t)):h([this.dlayers[r+1]],a(this.weights[r+1]))[0],this.shape[r+1].daf&&(t=s(t,g(this.layers[r],e=>this.shape[r+1].daf(e)))),this.dlayers[r]=t,this.dlayers[r-1]=new Array(this.shape[r].d).fill(0).map((e,s)=>new Array(this.shape[r].h).fill(0).map((e,h)=>new Array(this.shape[r].w).fill(0).map((e,a)=>t[s*this.shape[r].h*this.shape[r].w+h*this.shape[r].h+a])))}else if(this.shape[r].type==A.CONV){const e=u(this.weights[r],this.dlayers[r],this.layers[r-1],this.shape[r].s,this.shape[r].p),{dF:h,dI:a,dB:i}=e;this.dlayers[r-1]=a,this.shape[r].daf&&(this.dlayers[r-1]=s(this.dlayers[r-1],g(this.layers[r-1],e=>this.shape[r].daf(e)))),t&&(this.weights[r]=y(this.weights[r],h,this.learningRate)),t&&(this.biases[r]=this.biases[r].map((e,t)=>e+i[t]*this.learningRate))}else if(this.shape[r].type==A.POOL){let e=new Array(this.shape[r-1].d).fill(0).map(()=>new Array(this.shape[r-1].h).fill(0).map(()=>new Array(this.shape[r-1].w).fill(0))),t=p(this.layers[r-1],this.shape[r].f,this.shape[r].s,!0);for(let s=0;s<this.shape[r].d;s++)for(let h=0;h<this.shape[r].h;h++)for(let a=0;a<this.shape[r].w;a++){let i=t[s][h][a];e[s][i.y][i.x]=this.dlayers[r][s][h][a]}this.dlayers[r-1]=e,this.shape[r].daf&&(this.dlayers[r-1]=s(this.dlayers[r-1],g(this.layers[r-1],e=>this.shape[r].daf(e))))}g(this.dlayers[r],e=>{if(isNaN(e))throw new Error(`[${r}] output ${e} after derivation`);return e})}}updateWeights(){for(let e=this.shape.length-1;e>0;e--)if(this.shape[e].type==A.FC)for(let t=0;t<this.weights[e].length;t++)for(let r=0;r<this.weights[e][t].length;r++)this.weights[e][t][r]+=this.layers[e-1][t]*this.dlayers[e][r]*this.learningRate,this.dlayers[e][r]=0;else if(this.shape[e].type==A.CONV){const t=u(this.weights[e],this.dlayers[e],this.layers[e-1],this.shape[e].s,this.shape[e].p),{dF:r,dI:s,dB:h}=t;this.weights[e]=y(this.weights[e],r,this.learningRate),this.biases[e]=this.biases[e].map((e,t)=>e+h[t]*this.learningRate)}}static confirmShape(e){if(e[0].type!=A.INPUT)throw new Error("the first layer isn't an input layer, instead is: "+e[0].type);for(let t=1;t<e.length;t++)if(e[t].type==A.CONV){if(e[t].w!=(e[t-1].w-e[t].f+2*e[t].p)/e[t].s+1)throw new Error(`[${t}] CONV: outW doesn't equal to calculated outW expected: ${(e[t-1].w-e[t].f+2*e[t].p)/e[t].s+1}, actual: ${e[t].w}`);if(e[t].h!=(e[t-1].h-e[t].f+2*e[t].p)/e[t].s+1)throw new Error(`[${t}] CONV: outH doesn't equal to calculated outH expected: ${(e[t-1].h-e[t].f+2*e[t].p)/e[t].s+1}, actual: ${e[t].h}`);if(e[t].d!=e[t].k)throw new Error(`[${t}] CONV: number of kernels doesn't equal outD kernels: ${e[t].k}, outD: ${e[t].d}`)}else if(e[t].type==A.POOL){if(e[t].w!=(e[t-1].w-e[t].f)/e[t].s+1)throw new Error(`[${t}] POOL: outW doesn't equal to calculated outW expected: ${(e[t-1].w-e[t].f)/e[t].s+1}, actual: ${e[t].w}`);if(e[t].h!=(e[t-1].h-e[t].f)/e[t].s+1)throw new Error(`[${t}] POOL: outH doesn't equal to calculated outH expected: ${(e[t-1].h-e[t].f)/e[t].s+1}, actual: ${e[t].h}`);if(e[t-1].d!=e[t].d)throw new Error(`[${t}] POOL: outD doesn't equal inZ inZ: ${e[t-1].d}, outD: ${e[t].d}`)}else if(e[t].type==A.FC){if(e[t-1].type!=A.FC&&e[t-1].type!=A.FLATTEN)throw new Error(`[${t}] FC: The previous layer should be type FC or FLATTEN`)}else if(e[t].type==A.FLATTEN&&(e[t-1].type==A.FLATTEN||e[t-1].type==A.FC))throw new Error(`[${t}] FLATTEN: The previous layer can't be flat`);return!0}}const A={CONV:0,POOL:1,FC:2,INPUT:3,FLATTEN:4},O={RELU:"RELU",SIGMOID:"SIGMOID",TANH:"TANH"},T={INPUT:function(e,t,r){this.type=A.INPUT,this.w=e,this.h=t,this.d=r},CONV:function(e,t,r,s,h,a,i,n){this.type=A.CONV,this.w=e,this.h=t,this.d=r,this.f=s,this.k=h,this.s=a,this.p=i,this.afName=n},POOL:function(e,t,r,s,h,a){this.type=A.POOL,this.w=e,this.h=t,this.d=r,this.f=s,this.s=h,this.afName=a},FC:function(e,t){this.type=A.FC,this.l=e,this.afName=t},FLATTEN:function(e,t,r){this.type=A.FLATTEN,this.w=e,this.h=t,this.d=r,this.l=e*t*r}},E={LeNet5:[new T.INPUT(32,32,1),new T.CONV(28,28,6,5,6,1,0,O.TANH),new T.POOL(14,14,6,2,2,O.TANH),new T.CONV(10,10,16,5,16,1,0,O.TANH),new T.POOL(5,5,16,2,2,O.TANH),new T.CONV(1,1,120,5,120,1,0,O.TANH),new T.FLATTEN(1,1,120),new T.FC(84,O.TANH),new T.FC(10,O.TANH)],LeNet5Color:[new T.INPUT(32,32,3),new T.CONV(28,28,6,5,6,1,0,O.TANH),new T.POOL(14,14,6,2,2,O.TANH),new T.CONV(10,10,16,5,16,1,0,O.TANH),new T.POOL(5,5,16,2,2,O.TANH),new T.CONV(1,1,120,5,120,1,0,O.TANH),new T.FLATTEN(1,1,120),new T.FC(84,O.TANH),new T.FC(10,O.TANH)]};e.exports={CNN:N,ActivationFunction:O,Layer:T,NetworkArchitectures:E,LayerType:A}},function(e,t){const r=e=>{const t=(e,r)=>e.length?t(e[0],r+1):r;return t(e,0)},s=(e,t)=>e.map((e,r,h)=>e&&e.length?s(e,t):t(e,r,h)),h=(e,t)=>{if(e.length!=t.length)throw new Error("invalid dimensions, both arrays should have equal shape");if(e[0]instanceof Array&&t[0]instanceof Array){const r=[];for(let s=0;s<e.length;s++)r[s]=h(e[s],t[s]);return r}if(e[0]instanceof Array!=t[0]instanceof Array)throw new Error("invalid dimensions, both arrays should have equal shape");{const r=[];for(let s=0;s<e.length;s++)r[s]=e[s]*t[s];return r}},a=(e,t)=>{if(e.length!=t.length)throw new Error("invalid dimensions, both arrays should have equal shape");if(e[0]instanceof Array&&t[0]instanceof Array){const r=[];for(let s=0;s<e.length;s++)r[s]=a(e[s],t[s]);return r}if(e[0]instanceof Array!=t[0]instanceof Array)throw new Error("invalid dimensions, both arrays should have equal shape");{const r=[];for(let s=0;s<e.length;s++)r[s]=e[s]+t[s];return r}},i=e=>{if(1==r(e))return i([[[e]]])[0][0][0];if(2==r(e))return i([[e]])[0][0];if(3==r(e))return i([e])[0];{const t=[];for(let r=0;r<e.length;r++){t[r]=[];for(let s=0;s<e[r].length;s++){t[r][s]=[];for(let h=0;h<e[r][s].length;h++){t[r][s][h]=[];for(let a=0;a<e[r][s][h].length;a++)t[r][s][h][a]=e[r][s][e[r][s].length-h-1][e[r][s][h].length-a-1]}}}return t}},n=(e,t,r=1,s=0,h=null)=>{if(t[0].length!=e.length)throw new Error(`filter depth(${t[0].length}) doesnt match input depth(${e.length})`);if(t[0][0].length!=t[0][0][0].length)throw new Error(`filter should be a square matrix(${t[0][0].length} != ${t[0][0][0].length})`);if(h&&h.length!=t.length)throw new Error(`bias depth(${h.length}), should match output depth(${t.length})`);const a=t[0][0].length,i=e.length,n=parseInt((e[0].length-a+2*s)/r+1),l=parseInt((e[0][0].length-a+2*s)/r+1);return t.map((t,o)=>{const p=[];for(let f=0;f<n;f++){p[f]=[];for(let n=0;n<l;n++){let l=h?h[o]:0;for(let h=0;h<i;h++)for(let i=0;i<a;i++)for(let o=0;o<a;o++){const a=f*r+i-s,p=n*r+o-s;a>=0&&a<e[0].length&&p>=0&&p<e[0][0].length&&(l+=e[h][a][p]*t[h][i][o])}p[f][n]=l}}return p})},l=e=>{let t=-1/0;return s(e,e=>{e>t&&(t=e)}),t},o=e=>{let t=0;return s(e,e=>{t+=e}),t},p=(e,t,r)=>e.map((s,h)=>s&&s.length?p(e[h],t[h],r):e[h]+t[h]*r),f=e=>e.reduce((e,t)=>t.length?e.concat(f(t)):e.concat(t),[]),d=e=>e.map(e=>e instanceof Array?d(e):0);e.exports={matrixMultiply:h,matrixDot:(e,t)=>{if(e[0].length!=t.length)throw new Error(`invalid dimensions a -> x (${e[0].length}) should equal b -> y (${t.length})`);const r=[];for(let s=0;s<e.length;s++){r[s]=[];for(let h=0;h<t[0].length;h++){r[s][h]=0;for(let a=0;a<e[s].length;a++)r[s][h]+=e[s][a]*t[a][h]}}return r},transpose:e=>{if(r(e)>2)throw new Error("transpose supports up to 2d arrays");e[0].length||(e=[e]);const t=[];for(let r=0;r<e[0].length;r++){t[r]=[];for(let s=0;s<e.length;s++)t[r][s]=e[s][r]}return t},convolute:(e,t,r=1,s=0,h=null)=>n(e,i(t),r,s,h),doubleInverse:i,correlate:n,getDimension:r,maxPool:(e,t,s,h=!1)=>{if(3==r(e))return e.map(e=>{const r=(e.length-t)/s+1,a=(e[0].length-t)/s+1;let i=[];for(let n=0;n<r;n++){i[n]=[];for(let r=0;r<a;r++){let a=e[n*s][r*s],l={x:r*s,y:n*s};for(let h=0;h<t;h++)for(let i=0;i<t;i++){let t=n*s+h,o=r*s+i;e[t][o]>a&&(a=e[t][o],l={x:o,y:t})}i[n][r]=h?l:a}}return i});throw new Error(`invalid array dimension (${r(e)}), should be 3`)},flattenDeep:f,matrixAdd:a,deepMap:s,backPropagateCorrelation:(e,t,s,h,a)=>{if(3==r(s)&&4==r(e)){if(e[0].length!=s.length)throw new Error("filter depth doesnt match input depth");const r=[];for(let i=0;i<e.length;i++){r[i]=[];for(let n=0;n<e[i].length;n++){r[i][n]=[];for(let l=0;l<e[i][n].length;l++){r[i][n][l]=new Array(e[i][n][l].length).fill(0);for(let o=0;o<e[i][n][l].length;o++)for(let e=0;e<t[i].length;e++)for(let p=0;p<t[i][e].length;p++){const f=e*h+a+l,d=p*h+a+o;f>=0&&f<s[n].length&&d>=0&&d<s[n][f].length&&(r[i][n][l][o]+=t[i][e][p]*s[n][f][d])}}}}const i=[];for(let r=0;r<e.length;r++)for(let n=0;n<s.length;n++){i[n]=[];for(let l=0;l<s[n].length;l++){i[n][l]=new Array(s[n][l].length).fill(0);for(let o=0;o<s[n][l].length;o++)for(let s=0;s<t[r].length;s++)for(let p=0;p<t[r][s].length;p++){const f=l-s*h+a,d=o-p*h+a;i[n][l]||(i[n][l]=[]),f>=0&&f<e[r][n].length&&d>=0&&d<e[r][n][f].length&&(i[n][l][o]+=t[r][s][p]*e[r][n][f][d])}}}return{dF:r,dI:i,dB:t.map(e=>o(e))}}throw new Error(`invalid array dimension (${r(s)}, ${r(e)})`)},update2Dmatrix:p,max:l,sum:o,softmax:e=>{const t=o(e);return s(e,e=>e/t)},maxIndex:e=>{if(1==r(e)){let t=e[0],r=0;for(let s=1;s<e.length;s++)e[s]>t&&(t=e[s],r=s);return r}throw new Error("maxIndex works only on 1d arrays")},deepNormalize:(e,t)=>(t||(t=l(e)),s(e,e=>e/t)),vectorize:(e,t)=>{const r=new Array(t).fill(0);return r[e]=1,r},deepCopyArrayShape:d}}]);